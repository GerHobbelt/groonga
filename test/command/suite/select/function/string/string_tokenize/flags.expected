plugin_register functions/string
[[0,0.0,0.0],true]
table_create Lexicon TABLE_PAT_KEY ShortText   --normalizer NormalizerNFKC121   --default_tokenizer TokenNgram
[[0,0.0,0.0],true]
table_tokenize Lexicon "ぐるんが" --mode ADD
[
  [
    0,
    0.0,
    0.0
  ],
  [
    {
      "value": "ぐる",
      "position": 0,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "るん",
      "position": 1,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "んが",
      "position": 2,
      "force_prefix": false,
      "force_prefix_search": false
    },
    {
      "value": "が",
      "position": 3,
      "force_prefix": false,
      "force_prefix_search": false
    }
  ]
]
table_create Memos TABLE_HASH_KEY ShortText
[[0,0.0,0.0],true]
load --table Memos
[
{"_key": "ぐるんが"}
]
[[0,0.0,0.0],1]
select Memos   --output_columns '_key, string_tokenize(_key, Lexicon, {"flags": "NONE"})'
[
  [
    0,
    0.0,
    0.0
  ],
  [
    [
      [
        1
      ],
      [
        [
          "_key",
          "ShortText"
        ],
        [
          "string_tokenize",
          null
        ]
      ],
      [
        "ぐるんが",
        [
          "ぐる",
          "るん",
          "んが"
        ]
      ]
    ]
  ]
]
