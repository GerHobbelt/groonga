# -*- po -*-
# English translations for Groonga package.
# Copyright (C) 2009-2022 Groonga Project
# This file is distributed under the same license as the Groonga package.
# Automatically generated, 2022.
#
msgid ""
msgstr ""
"Project-Id-Version: Groonga 12.0.1\n"
"Report-Msgid-Bugs-To: \n"
"PO-Revision-Date: 2022-02-28 11:57+0900\n"
"Last-Translator: Automatically generated\n"
"Language-Team: none\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: en\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

msgid "``TokenBigram``"
msgstr "``TokenBigram``"

msgid "Summary"
msgstr "Summary"

msgid ""
"``TokenBigram`` is a bigram based tokenizer. It's recommended to use this "
"tokenizer for most cases."
msgstr ""
"``TokenBigram`` is a bigram based tokenizer. It's recommended to use this "
"tokenizer for most cases."

msgid ""
"Bigram tokenize method tokenizes a text to two adjacent characters tokens. "
"For example, ``Hello`` is tokenized to the following tokens:"
msgstr ""
"Bigram tokenize method tokenizes a text to two adjacent characters tokens. "
"For example, ``Hello`` is tokenized to the following tokens:"

msgid "``He``"
msgstr "``He``"

msgid "``el``"
msgstr "``el``"

msgid "``ll``"
msgstr "``ll``"

msgid "``lo``"
msgstr "``lo``"

msgid ""
"Bigram tokenize method is good for recall because you can find all texts by "
"query consists of two or more characters."
msgstr ""
"Bigram tokenize method is good for recall because you can find all texts by "
"query consists of two or more characters."

msgid ""
"In general, you can't find all texts by query consists of one character "
"because one character token doesn't exist. But you can find all texts by "
"query consists of one character in Groonga. Because Groonga find tokens that "
"start with query by predictive search. For example, Groonga can find ``ll`` "
"and ``lo`` tokens by ``l`` query."
msgstr ""
"In general, you can't find all texts by query consists of one character "
"because one character token doesn't exist. But you can find all texts by "
"query consists of one character in Groonga. Because Groonga find tokens that "
"start with query by predictive search. For example, Groonga can find ``ll`` "
"and ``lo`` tokens by ``l`` query."

msgid ""
"Bigram tokenize method isn't good for precision because you can find texts "
"that includes query in word. For example, you can find ``world`` by ``or``. "
"This is more sensitive for ASCII only languages rather than non-ASCII "
"languages. ``TokenBigram`` has solution for this problem described in the "
"below."
msgstr ""
"Bigram tokenize method isn't good for precision because you can find texts "
"that includes query in word. For example, you can find ``world`` by ``or``. "
"This is more sensitive for ASCII only languages rather than non-ASCII "
"languages. ``TokenBigram`` has solution for this problem described in the "
"below."

msgid "Syntax"
msgstr "Syntax"

msgid "``TokenBigram`` hasn't parameter::"
msgstr "``TokenBigram`` hasn't parameter::"

msgid "Usage"
msgstr "Usage"

msgid ""
"``TokenBigram`` behavior is different when it's worked with any :doc:`/"
"reference/normalizers`."
msgstr ""
"``TokenBigram`` behavior is different when it's worked with any :doc:`/"
"reference/normalizers`."

msgid ""
"If no normalizer is used, ``TokenBigram`` uses pure bigram (all tokens "
"except the last token have two characters) tokenize method:"
msgstr ""
"If no normalizer is used, ``TokenBigram`` uses pure bigram (all tokens "
"except the last token have two characters) tokenize method:"

msgid "Execution example::"
msgstr "Execution example::"

msgid ""
"If normalizer is used, ``TokenBigram`` uses white-space-separate like "
"tokenize method for ASCII characters. ``TokenBigram`` uses bigram tokenize "
"method for non-ASCII characters."
msgstr ""
"If normalizer is used, ``TokenBigram`` uses white-space-separate like "
"tokenize method for ASCII characters. ``TokenBigram`` uses bigram tokenize "
"method for non-ASCII characters."

msgid ""
"You may be confused with this combined behavior. But it's reasonable for "
"most use cases such as English text (only ASCII characters) and Japanese "
"text (ASCII and non-ASCII characters are mixed)."
msgstr ""
"You may be confused with this combined behavior. But it's reasonable for "
"most use cases such as English text (only ASCII characters) and Japanese "
"text (ASCII and non-ASCII characters are mixed)."

msgid ""
"Most languages consists of only ASCII characters use white-space for word "
"separator. White-space-separate tokenize method is suitable for the case."
msgstr ""
"Most languages consists of only ASCII characters use white-space for word "
"separator. White-space-separate tokenize method is suitable for the case."

msgid ""
"Languages consists of non-ASCII characters don't use white-space for word "
"separator. Bigram tokenize method is suitable for the case."
msgstr ""
"Languages consists of non-ASCII characters don't use white-space for word "
"separator. Bigram tokenize method is suitable for the case."

msgid "Mixed tokenize method is suitable for mixed language case."
msgstr "Mixed tokenize method is suitable for mixed language case."

msgid ""
"If you want to use bigram tokenize method for ASCII character, see "
"``TokenBigramSplitXXX`` type tokenizers such as :ref:`token-bigram-split-"
"symbol-alpha`."
msgstr ""
"If you want to use bigram tokenize method for ASCII character, see "
"``TokenBigramSplitXXX`` type tokenizers such as :ref:`token-bigram-split-"
"symbol-alpha`."

msgid "Let's confirm ``TokenBigram`` behavior by example."
msgstr "Let's confirm ``TokenBigram`` behavior by example."

msgid ""
"``TokenBigram`` uses one or more white-spaces as token delimiter for ASCII "
"characters:"
msgstr ""
"``TokenBigram`` uses one or more white-spaces as token delimiter for ASCII "
"characters:"

msgid ""
"``TokenBigram`` uses character type change as token delimiter for ASCII "
"characters. Character type is one of them:"
msgstr ""
"``TokenBigram`` uses character type change as token delimiter for ASCII "
"characters. Character type is one of them:"

msgid "Alphabet"
msgstr "Alphabet"

msgid "Digit"
msgstr "Digit"

msgid "Symbol (such as ``(``, ``)`` and ``!``)"
msgstr "Symbol (such as ``(``, ``)`` and ``!``)"

msgid "Hiragana"
msgstr "Hiragana"

msgid "Katakana"
msgstr "Katakana"

msgid "Kanji"
msgstr "Kanji"

msgid "Others"
msgstr "Others"

msgid "The following example shows two token delimiters:"
msgstr "The following example shows two token delimiters:"

msgid "at between ``100`` (digits) and ``cents`` (alphabets)"
msgstr "at between ``100`` (digits) and ``cents`` (alphabets)"

msgid "at between ``cents`` (alphabets) and ``!!!`` (symbols)"
msgstr "at between ``cents`` (alphabets) and ``!!!`` (symbols)"

msgid ""
"Here is an example that ``TokenBigram`` uses bigram tokenize method for non-"
"ASCII characters."
msgstr ""
"Here is an example that ``TokenBigram`` uses bigram tokenize method for non-"
"ASCII characters."
