Execution example::

  tokenize TokenDelimit "-˗֊‐‑‒–⁃⁻₋− ﹣－ ー—―─━ｰ" --token_filters 'TokenFilterNFKC150("unify_hyphen_and_prolonged_sound_mark", true)'
  # [
  #   [
  #     0,
  #     1337566253.89858,
  #     0.000355720520019531
  #   ],
  #   [
  #     {
  #       "value": "-----------",
  #       "position": 0,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "--",
  #       "position": 1,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "------",
  #       "position": 2,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     }
  #   ]
  # ]
