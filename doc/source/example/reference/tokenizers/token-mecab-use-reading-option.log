Execution example::

  tokenize 'TokenMecab("use_reading", true)' '彼の名前は山田さんのはずです。'
  # [
  #   [
  #     0,
  #     1337566253.89858,
  #     0.000355720520019531
  #   ],
  #   [
  #     {
  #       "value": "カレ",
  #       "position": 0,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "ノ",
  #       "position": 1,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "ナマエ",
  #       "position": 2,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "ハ",
  #       "position": 3,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "ヤマダ",
  #       "position": 4,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "サン",
  #       "position": 5,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "ノ",
  #       "position": 6,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "ハズ",
  #       "position": 7,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "デス",
  #       "position": 8,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     },
  #     {
  #       "value": "。",
  #       "position": 9,
  #       "force_prefix": false,
  #       "force_prefix_search": false
  #     }
  #   ]
  # ]
